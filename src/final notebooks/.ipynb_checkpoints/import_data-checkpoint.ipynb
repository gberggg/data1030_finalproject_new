{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b0f79fc6-0099-4cc8-9fda-b2e55475d017",
   "metadata": {},
   "source": [
    "### This script is for downloading data from the BEACO2N portal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bf4590b9-a319-462f-8fb7-cbd81521239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Packages\n",
    "import pandas as pd\n",
    "from datetime import datetime,timedelta,timezone\n",
    "import pytz\n",
    "import smtplib\n",
    "import numpy as np\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5c22f27-2ad8-46a7-b55a-9cf803c3521c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2022-12-31%2020:00:00\n"
     ]
    }
   ],
   "source": [
    "# Defining variables and inputs\n",
    "\n",
    "# List of variables to download\n",
    "vars_of_interest = ['rh','temp','no_wrk_aux','no2_wrk_aux','o3_wrk_aux']\n",
    "interval = 60 \n",
    "\n",
    "# Read in the sensor keys\n",
    "sensors = pd.read_csv('data/sensor_key.csv')\n",
    "\n",
    "# Set the url lead\n",
    "url_lead = \"http://128.32.208.8/node/\"\n",
    "\n",
    "# Create a string version of the variables of interest in order to read from the url\n",
    "all_vars = \",\".join(vars_of_interest)\n",
    "\n",
    "# Establish start and end dates\n",
    "start_date = \"2022-12-31\"\n",
    "start_time = \"20:00:00\"\n",
    "end_date = \"2023-12-31\"\n",
    "end_time = \"23:00:00\"\n",
    "end_string = end_date +\"%20\"+end_time\n",
    "start_string = start_date+\"%20\"+start_time\n",
    "\n",
    "print(start_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b6ec5adb-736a-49a0-a7fe-9979559a25dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For downloading data from multiple sensors, if interested\n",
    "\n",
    "# Create an empty list to store the DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Loop to iterate through sensors, download data, and append into a single dataframe\n",
    "for index, row in sensors.iterrows():\n",
    "    try:\n",
    "        # Print each row (for debugging purposes)\n",
    "       # print(row)\n",
    "        \n",
    "        # Take the name of the sensor and replace spaces for URL encoding\n",
    "        name = row['name']\n",
    "        name_url = name.replace(\" \", \"%20\")\n",
    "        \n",
    "        # Take the node ID\n",
    "        node_id = row['node_id']\n",
    "        \n",
    "        # Build the URL string\n",
    "        addr = (f\"{url_lead}{node_id}/measurements_all/csv?\"\n",
    "                f\"name={name_url}&interval={interval}&variables={all_vars}&start={start_string}&end={end_string}&chart_type=measurement\")\n",
    "\n",
    "        # Request data\n",
    "        with urllib.request.urlopen(addr) as response:\n",
    "            data = response.read()\n",
    "\n",
    "        # Decode the data and transform it into a list of rows\n",
    "        data = data.decode().strip('\\r\\n').split(\"\\r\\n\")\n",
    "        data = [x.split(',') for x in data]\n",
    "\n",
    "        # Transform into a df with the first row as column headers\n",
    "        df = pd.DataFrame(data[1:], columns=data[0])\n",
    "        \n",
    "        # Add a column to indicate the sensor name\n",
    "        df['sensor_name'] = name\n",
    "\n",
    "        # Append the df to the list\n",
    "        dfs.append(df)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error with sensor {name}: {e}\")\n",
    "\n",
    "# Concatenate all dfs in the list into a single dataframe\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "6ff0953c-26c4-48c7-8126-6f1e0998021f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For downloading just Sensor01, for this project\n",
    "\n",
    "node_id = 250\n",
    "name = \"Myron J Francis Elementary\"\n",
    "name_url = name.replace(\" \", \"%20\")\n",
    "\n",
    "addr = (f\"{url_lead}{node_id}/measurements_all/csv?\"\n",
    "        f\"name={name_url}&interval={interval}&variables={all_vars}&start={start_string}&end={end_string}&chart_type=measurement\")\n",
    "\n",
    "with urllib.request.urlopen(addr) as response:\n",
    "    data = response.read()\n",
    "\n",
    "data = data.decode().strip('\\r\\n').split(\"\\r\\n\")\n",
    "data = [x.split(',') for x in data]\n",
    "\n",
    "df = pd.DataFrame(data[1:], columns=data[0])\n",
    "\n",
    "df['sensor_name'] = name\n",
    "\n",
    "#print(df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "70d22128-5ec1-4543-9c79-f709543ab271",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25\n",
      "       local_timestamp         epoch             datetime node_file_id  \\\n",
      "0  2022-12-31 20:00:00  1672545600.0  2023-01-01 04:00:00      3362493   \n",
      "1  2022-12-31 21:00:00  1672549200.0  2023-01-01 05:00:00      3362494   \n",
      "2  2022-12-31 22:00:00  1672552800.0  2023-01-01 06:00:00      3362495   \n",
      "3  2022-12-31 23:00:00  1672556400.0  2023-01-01 07:00:00      3362496   \n",
      "4  2023-01-01 00:00:00  1672560000.0  2023-01-01 08:00:00      3362497   \n",
      "\n",
      "                  rh                temp            no_wrk_aux  \\\n",
      "0  72.57809316666666           14.601538  0.030025999999999997   \n",
      "1          72.939627          14.2900125  0.029816666666666714   \n",
      "2  73.19682083333333  14.447597666666667   0.02976833333333334   \n",
      "3  73.28262116666667  14.222536166666666  0.030214833333333302   \n",
      "4         72.6791165  15.031594666666667  0.029871499999999995   \n",
      "\n",
      "            no2_wrk_aux            o3_wrk_aux node_id  \\\n",
      "0  0.015573999999999977   0.03254566666666664     250   \n",
      "1  0.015689999999999982   0.03211966666666666     250   \n",
      "2  0.016166166666666704  0.030329833333333334     250   \n",
      "3   0.01678850000000004  0.029625999999999986     250   \n",
      "4  0.015290166666666716  0.028746333333333318     250   \n",
      "\n",
      "                   sensor_name                   datenum  \\\n",
      "0  Myron J. Francis Elementary 2023-01-01 04:00:00+00:00   \n",
      "1  Myron J. Francis Elementary 2023-01-01 05:00:00+00:00   \n",
      "2  Myron J. Francis Elementary 2023-01-01 06:00:00+00:00   \n",
      "3  Myron J. Francis Elementary 2023-01-01 07:00:00+00:00   \n",
      "4  Myron J. Francis Elementary 2023-01-01 08:00:00+00:00   \n",
      "\n",
      "                       date  \n",
      "0 2022-12-31 23:00:00-05:00  \n",
      "1 2023-01-01 00:00:00-05:00  \n",
      "2 2023-01-01 01:00:00-05:00  \n",
      "3 2023-01-01 02:00:00-05:00  \n",
      "4 2023-01-01 03:00:00-05:00  \n"
     ]
    }
   ],
   "source": [
    "# Ensure correct time zone for combined data, for  multiple sensors\n",
    "\n",
    "combined_df['datenum'] = pd.to_datetime(combined_df['datetime'],format = '%Y-%m-%d %H:%M:%S',utc = True)\n",
    "combined_df['date'] = combined_df['datenum'].dt.tz_convert('US/Eastern')\n",
    "\n",
    "print(len(pd.unique(combined_df['node_id'])))\n",
    "\n",
    "print(combined_df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c488b46f-678e-4d0e-9273-15fcb1a99e09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "       local_timestamp         epoch             datetime node_file_id  \\\n",
      "0  2022-12-31 20:00:00  1672545600.0  2023-01-01 04:00:00      3362493   \n",
      "1  2022-12-31 21:00:00  1672549200.0  2023-01-01 05:00:00      3362494   \n",
      "2  2022-12-31 22:00:00  1672552800.0  2023-01-01 06:00:00      3362495   \n",
      "3  2022-12-31 23:00:00  1672556400.0  2023-01-01 07:00:00      3362496   \n",
      "4  2023-01-01 00:00:00  1672560000.0  2023-01-01 08:00:00      3362497   \n",
      "\n",
      "                  rh                temp            no_wrk_aux  \\\n",
      "0  72.57809316666666           14.601538  0.030025999999999997   \n",
      "1          72.939627          14.2900125  0.029816666666666714   \n",
      "2  73.19682083333333  14.447597666666667   0.02976833333333334   \n",
      "3  73.28262116666667  14.222536166666666  0.030214833333333302   \n",
      "4         72.6791165  15.031594666666667  0.029871499999999995   \n",
      "\n",
      "            no2_wrk_aux            o3_wrk_aux node_id  \\\n",
      "0  0.015573999999999977   0.03254566666666664     250   \n",
      "1  0.015689999999999982   0.03211966666666666     250   \n",
      "2  0.016166166666666704  0.030329833333333334     250   \n",
      "3   0.01678850000000004  0.029625999999999986     250   \n",
      "4  0.015290166666666716  0.028746333333333318     250   \n",
      "\n",
      "                  sensor_name                   datenum  \\\n",
      "0  Myron J Francis Elementary 2023-01-01 04:00:00+00:00   \n",
      "1  Myron J Francis Elementary 2023-01-01 05:00:00+00:00   \n",
      "2  Myron J Francis Elementary 2023-01-01 06:00:00+00:00   \n",
      "3  Myron J Francis Elementary 2023-01-01 07:00:00+00:00   \n",
      "4  Myron J Francis Elementary 2023-01-01 08:00:00+00:00   \n",
      "\n",
      "                       date  \n",
      "0 2022-12-31 23:00:00-05:00  \n",
      "1 2023-01-01 00:00:00-05:00  \n",
      "2 2023-01-01 01:00:00-05:00  \n",
      "3 2023-01-01 02:00:00-05:00  \n",
      "4 2023-01-01 03:00:00-05:00  \n"
     ]
    }
   ],
   "source": [
    "# Ensure correct time zone for sensor01, for this project\n",
    "\n",
    "df['datenum'] = pd.to_datetime(df['datetime'],format = '%Y-%m-%d %H:%M:%S',utc = True)\n",
    "df['date'] = df['datenum'].dt.tz_convert('US/Eastern')\n",
    "\n",
    "print(len(pd.unique(df['node_id'])))\n",
    "\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "753542f6-0a94-48f8-8cc3-db2fae05d26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up columns (combined_df)\n",
    "\n",
    "combined_df = combined_df[[\"date\",\"node_id\",\"sensor_name\",\"no_wrk_aux\",\"no2_wrk_aux\",\"o3_wrk_aux\",\"temp\",\"rh\"]]\n",
    "\n",
    "# Export as CSV \n",
    "\n",
    "combined_df.to_csv(\"data/raw_data//lcs_all.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "469fd028-d689-4b09-8e67-12403a19b89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean up columns (sensor01)\n",
    "\n",
    "df = df[[\"date\",\"node_id\",\"sensor_name\",\"no_wrk_aux\",\"no2_wrk_aux\",\"o3_wrk_aux\",\"temp\",\"rh\"]]\n",
    "\n",
    "# Export as CSV \n",
    "\n",
    "df.to_csv(\"data/raw_data/sensor1.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48e29ca-d673-44c2-a92a-f9a37c02d6d3",
   "metadata": {},
   "source": [
    "### This script is for downloading and cleaning up reference data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1b9c648f-a04d-4da3-9adf-2595e86fef1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state_code                object\n",
      "county_code               object\n",
      "site_number               object\n",
      "parameter_code            object\n",
      "poc                        int64\n",
      "latitude                 float64\n",
      "longitude                float64\n",
      "datum                     object\n",
      "parameter                 object\n",
      "date_local                object\n",
      "time_local                object\n",
      "date_gmt                  object\n",
      "time_gmt                  object\n",
      "sample_measurement       float64\n",
      "units_of_measure          object\n",
      "units_of_measure_code     object\n",
      "sample_duration           object\n",
      "sample_duration_code      object\n",
      "sample_frequency          object\n",
      "detection_limit          float64\n",
      "uncertainty               object\n",
      "qualifier                 object\n",
      "method_type               object\n",
      "method                    object\n",
      "method_code               object\n",
      "state                     object\n",
      "county                    object\n",
      "date_of_last_change       object\n",
      "cbsa_code                 object\n",
      "Header                    object\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "from pandas import json_normalize\n",
    "\n",
    "# NO2 for 2023\n",
    "url_2 = \"https://aqs.epa.gov/data/api/sampleData/bySite?email=grace_berg@brown.edu&key= sandkit51&param=42602&bdate=20230101&edate=20231231&state=44&county=007&site=1010\"  \n",
    "response_2 = requests.get(url_2)\n",
    "\n",
    "# parse out the json file\n",
    "ref = response_2.json() \n",
    "ref_df = json_normalize(ref, record_path=['Data'], meta=['Header'])\n",
    "\n",
    "ref_df = pd.DataFrame(ref_df)\n",
    "print(ref_df.dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47eacd05-ac03-4468-948c-3f0a49e4386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     date_gmt time_gmt  sample_measurement\n",
      "0  2023-01-01    05:00                 4.6\n",
      "1  2023-01-01    06:00                 6.6\n",
      "2  2023-01-01    07:00                 8.1\n",
      "3  2023-01-01    08:00                 4.7\n",
      "4  2023-01-01    09:00                 6.0\n"
     ]
    }
   ],
   "source": [
    "# clean up columns and filter for just FEM\n",
    "ref_df_FRM = ref_df[ref_df[\"method_type\"] == \"FRM\"]\n",
    "ref_df_FRM = ref_df_FRM[[\"date_gmt\",\"time_gmt\",\"sample_measurement\"]]\n",
    "\n",
    "print(ref_df_FRM.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11271d69-8ec2-432d-a16a-fce1e83ba5c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       date  sample_measurement\n",
      "0 2023-01-01 00:00:00-05:00                 4.6\n",
      "1 2023-01-01 01:00:00-05:00                 6.6\n",
      "2 2023-01-01 02:00:00-05:00                 8.1\n",
      "3 2023-01-01 03:00:00-05:00                 4.7\n",
      "4 2023-01-01 04:00:00-05:00                 6.0\n"
     ]
    }
   ],
   "source": [
    "# fix up dates\n",
    "ref_df_FRM[\"datetime_gmt\"] = pd.to_datetime(ref_df_FRM[\"date_gmt\"]+\" \"+ref_df_FRM[\"time_gmt\"], format = \"%Y-%m-%d %H:%M\",utc = True)\n",
    "ref_df_FRM['date'] = ref_df_FRM['datetime_gmt'].dt.tz_convert('US/Eastern')\n",
    "\n",
    "# clean up columns\n",
    "ref_df_FRM = ref_df_FRM[[\"date\",\"sample_measurement\"]]\n",
    "\n",
    "print(ref_df_FRM.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "70a0ea2e-8b8c-42af-b78e-81daa99622eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                       date  sample_measurement\n",
      "0 2023-01-01 00:00:00-05:00                 4.6\n",
      "1 2023-01-01 01:00:00-05:00                 6.6\n",
      "2 2023-01-01 02:00:00-05:00                 8.1\n",
      "3 2023-01-01 03:00:00-05:00                 4.7\n",
      "4 2023-01-01 04:00:00-05:00                 6.0\n",
      "(8760, 2)\n"
     ]
    }
   ],
   "source": [
    "ref_df_FRM_sorted = ref_df_FRM.sort_values(by='date')\n",
    "\n",
    "print(ref_df_FRM_sorted.head())\n",
    "print(ref_df_FRM_sorted.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "16fd65e5-a0ec-49fd-a788-486c613df1f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "ref_df_FRM_sorted.to_csv(\"data/raw_data/ref_no2.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7dbb297-0978-4789-8ca8-13042d74ce59",
   "metadata": {},
   "source": [
    "### Merge the LCS and ref datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a2d2c137-dc7b-413c-8113-3f0600a25ff7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                           date  node_id                 sensor_name  \\\n",
      "8756  2023-12-31 19:00:00-05:00    250.0  Myron J Francis Elementary   \n",
      "8757  2023-12-31 20:00:00-05:00    250.0  Myron J Francis Elementary   \n",
      "8758  2023-12-31 21:00:00-05:00    250.0  Myron J Francis Elementary   \n",
      "8759  2023-12-31 22:00:00-05:00    250.0  Myron J Francis Elementary   \n",
      "8760  2023-12-31 23:00:00-05:00    250.0  Myron J Francis Elementary   \n",
      "\n",
      "      no_wrk_aux  no2_wrk_aux  o3_wrk_aux      temp         rh  no2_ref  \\\n",
      "8756    0.028996     0.016828    0.032537  5.977073  43.328031      2.3   \n",
      "8757    0.029229     0.016986    0.032351  5.887504  43.413484      2.8   \n",
      "8758    0.029243     0.016978    0.032274  5.793468  43.115099      3.0   \n",
      "8759    0.029201     0.016817    0.032102  5.777033  43.133355      2.8   \n",
      "8760    0.029029     0.017182    0.031892  5.683831  43.783367      3.6   \n",
      "\n",
      "      t_since_depl  \n",
      "8756          8755  \n",
      "8757          8756  \n",
      "8758          8757  \n",
      "8759          8758  \n",
      "8760          8759  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "# load data\n",
    "ref_df_FRM_sorted = pd.read_csv(\"data/raw_data/ref_no2.csv\")\n",
    "df = pd.read_csv(\"data/raw_data/sensor1.csv\")\n",
    "\n",
    "\n",
    "# rename ref column\n",
    "ref_df_FRM_sorted.rename(columns={'sample_measurement': 'no2_ref'}, inplace=True)\n",
    "\n",
    "# merge dfs based on date - OUTER join means keeping rows where one or the other dfs have a date... don't throw data away, even if introduces missing values\n",
    "merge_df = df.merge(ref_df_FRM_sorted,how='outer',on='date')\n",
    "\n",
    "merge_df = merge_df[[\"date\",\"node_id\",\"sensor_name\",\"no_wrk_aux\",\"no2_wrk_aux\",\"o3_wrk_aux\",\"temp\",\"rh\",\"no2_ref\"]]\n",
    "\n",
    "\n",
    "# remove the 2022 and 2024 datetimes that are in bc of time difference\n",
    "merge_df = merge_df[(merge_df[\"date\"] >= \"2023-01-01 00:00:00-05:00\") & \n",
    "                    (merge_df[\"date\"] <= \"2023-12-31 23:00:00-05:00\")]\n",
    "\n",
    "\n",
    "# Add a timestep column\n",
    "\n",
    "merge_df['t_since_depl'] = range(0, len(merge_df))\n",
    "\n",
    "print(merge_df.tail())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "18159ce3-4d8c-47d6-b875-5902f360d038",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# remove rows where the target value is missing data\n",
    "merge_df.dropna(subset=['no2_ref'], inplace=True)\n",
    "\n",
    "# save\n",
    "merge_df.to_csv(\"data/merged_data/merge.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c748d0c0-14d8-4928-bfc6-a39738cd433c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                        date  node_id                 sensor_name  no_wrk_aux  \\\n",
      "1  2023-01-01 00:00:00-05:00    250.0  Myron J Francis Elementary    0.029817   \n",
      "2  2023-01-01 01:00:00-05:00    250.0  Myron J Francis Elementary    0.029768   \n",
      "3  2023-01-01 02:00:00-05:00    250.0  Myron J Francis Elementary    0.030215   \n",
      "4  2023-01-01 03:00:00-05:00    250.0  Myron J Francis Elementary    0.029871   \n",
      "5  2023-01-01 04:00:00-05:00    250.0  Myron J Francis Elementary    0.029996   \n",
      "\n",
      "   no2_wrk_aux  o3_wrk_aux       temp         rh  no2_ref  t_since_depl  \n",
      "1     0.015690    0.032120  14.290012  72.939627      4.6             0  \n",
      "2     0.016166    0.030330  14.447598  73.196821      6.6             1  \n",
      "3     0.016789    0.029626  14.222536  73.282621      8.1             2  \n",
      "4     0.015290    0.028746  15.031595  72.679117      4.7             3  \n",
      "5     0.015841    0.027785  14.489438  72.387203      6.0             4  \n"
     ]
    }
   ],
   "source": [
    "print(merge_df.head())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
